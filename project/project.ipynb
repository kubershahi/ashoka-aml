{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3uVsBf1jacE"
   },
   "source": [
    "# AML Project - Abstractive Text Summarization\n",
    "\n",
    "Problem Statment: Given a news article, generate a short summary of one to two sentences for the article.\n",
    "\n",
    "The summary should be abstractive rather than extractive. In abstractive summarization, new sentences are generated as part of the summary and the sentences in the summary might not be present in the news article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quywxuE8jxy9"
   },
   "source": [
    "### Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "output_embedded_package_id": "1TA7HShfr2cnAW-d--z5RbXOqzAKiywKT"
    },
    "executionInfo": {
     "elapsed": 4140,
     "status": "ok",
     "timestamp": 1652119490916,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "2ghsLfkLj0KB",
    "outputId": "240bede0-e65c-4a1f-e9b7-3da1a4b26fb5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# splittin dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# evaluation metric\n",
    "from ignite.metrics import Rouge, RougeN, RougeL\n",
    "\n",
    "# visualisation\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.offline as pyo\n",
    " \n",
    "# pyo.init_notebook_mode() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CncrthEZ38un"
   },
   "source": [
    "### Importing the Indian News Summary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 1218,
     "status": "ok",
     "timestamp": 1652119503357,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "emf_JRKnkHqo",
    "outputId": "366131b1-5408-44c8-abf8-d4b4448b1cbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98396</th>\n",
       "      <td>A CRPF jawan was on Tuesday axed to death with...</td>\n",
       "      <td>CRPF jawan axed to death by Maoists in Chhatti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98397</th>\n",
       "      <td>'Uff Yeh', the first song from the Sonakshi Si...</td>\n",
       "      <td>First song from Sonakshi Sinha's 'Noor' titled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98398</th>\n",
       "      <td>According to reports, a new version of the 199...</td>\n",
       "      <td>'The Matrix' film to get a reboot: Reports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98399</th>\n",
       "      <td>A new music video shows rapper Snoop Dogg aimi...</td>\n",
       "      <td>Snoop Dogg aims gun at clown dressed as Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98400</th>\n",
       "      <td>Madhesi Morcha, an alliance of seven political...</td>\n",
       "      <td>Madhesi Morcha withdraws support to Nepalese g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1      Kunal Shah's credit card bill payment platform...   \n",
       "2      New Zealand defeated India by 8 wickets in the...   \n",
       "3      With Aegon Life iTerm Insurance plan, customer...   \n",
       "4      Speaking about the sexual harassment allegatio...   \n",
       "...                                                  ...   \n",
       "98396  A CRPF jawan was on Tuesday axed to death with...   \n",
       "98397  'Uff Yeh', the first song from the Sonakshi Si...   \n",
       "98398  According to reports, a new version of the 199...   \n",
       "98399  A new music video shows rapper Snoop Dogg aimi...   \n",
       "98400  Madhesi Morcha, an alliance of seven political...   \n",
       "\n",
       "                                                 summary  \n",
       "0      upGrad learner switches to career in ML & Al w...  \n",
       "1      Delhi techie wins free food from Swiggy for on...  \n",
       "2      New Zealand end Rohit Sharma-led India's 12-ma...  \n",
       "3      Aegon life iTerm insurance plan helps customer...  \n",
       "4      Have known Hirani for yrs, what if MeToo claim...  \n",
       "...                                                  ...  \n",
       "98396  CRPF jawan axed to death by Maoists in Chhatti...  \n",
       "98397  First song from Sonakshi Sinha's 'Noor' titled...  \n",
       "98398         'The Matrix' film to get a reboot: Reports  \n",
       "98399  Snoop Dogg aims gun at clown dressed as Trump ...  \n",
       "98400  Madhesi Morcha withdraws support to Nepalese g...  \n",
       "\n",
       "[98401 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_headline = pd.read_csv('dataset/news_headline.csv', header=0)\n",
    "df_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1652119505975,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "WUgqR2AkKjYQ",
    "outputId": "60bbc9dd-633f-426a-eef5-f339bffd57e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98401, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_headline.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA40dGgn4L-G"
   },
   "source": [
    "### Splitting the dataset in training and testing set (80-20) split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1652119509189,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "E7RMDvl4kIDn",
    "outputId": "a09336c3-8d97-4efe-a0f9-108a89bb0909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78720,) (78720,)\n",
      "(19681,) (19681,)\n",
      "78720 78720\n",
      "19681 19681\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_headline['text'], df_headline['summary'], test_size=0.2,random_state=25, shuffle=True)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "x_train_list, y_train_list = x_train.tolist(), y_train.tolist()\n",
    "x_test_list, y_test_list = x_test.tolist(), y_test.tolist()\n",
    "\n",
    "print(len(x_train_list), len(y_train_list))\n",
    "print(len(x_test_list), len(y_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dp1rzit3FRPQ"
   },
   "source": [
    "### Importing the Pegasus model, tokenizer, trainer, and training arguments for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12505,
     "status": "ok",
     "timestamp": 1652119523781,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "CpM9A-RakITP",
    "outputId": "6c2648dc-7d58-40a0-a8f8-eb109bf692f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizerFast, Trainer, TrainingArguments\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23608,
     "status": "ok",
     "timestamp": 1652119547385,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "EsV5o6VbkIgc",
    "outputId": "0df9fdb2-eabd-4d7b-c3c9-d435bd85fa4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 7.95 s, total: 20.5 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# tokenizer_cnn = PegasusTokenizerFast.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "# model_cnn = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-cnn_dailymail\").to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "EYg5mbmF5N3t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 8.25 s, total: 20.4 s\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer_large = PegasusTokenizerFast.from_pretrained(\"google/pegasus-large\")\n",
    "model_large = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\").to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='google/pegasus-large', vocab_size=96103, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask_2>', 'additional_special_tokens': ['<mask_1>', '<unk_2>', '<unk_3>', '<unk_4>', '<unk_5>', '<unk_6>', '<unk_7>', '<unk_8>', '<unk_9>', '<unk_10>', '<unk_11>', '<unk_12>', '<unk_13>', '<unk_14>', '<unk_15>', '<unk_16>', '<unk_17>', '<unk_18>', '<unk_19>', '<unk_20>', '<unk_21>', '<unk_22>', '<unk_23>', '<unk_24>', '<unk_25>', '<unk_26>', '<unk_27>', '<unk_28>', '<unk_29>', '<unk_30>', '<unk_31>', '<unk_32>', '<unk_33>', '<unk_34>', '<unk_35>', '<unk_36>', '<unk_37>', '<unk_38>', '<unk_39>', '<unk_40>', '<unk_41>', '<unk_42>', '<unk_43>', '<unk_44>', '<unk_45>', '<unk_46>', '<unk_47>', '<unk_48>', '<unk_49>', '<unk_50>', '<unk_51>', '<unk_52>', '<unk_53>', '<unk_54>', '<unk_55>', '<unk_56>', '<unk_57>', '<unk_58>', '<unk_59>', '<unk_60>', '<unk_61>', '<unk_62>', '<unk_63>', '<unk_64>', '<unk_65>', '<unk_66>', '<unk_67>', '<unk_68>', '<unk_69>', '<unk_70>', '<unk_71>', '<unk_72>', '<unk_73>', '<unk_74>', '<unk_75>', '<unk_76>', '<unk_77>', '<unk_78>', '<unk_79>', '<unk_80>', '<unk_81>', '<unk_82>', '<unk_83>', '<unk_84>', '<unk_85>', '<unk_86>', '<unk_87>', '<unk_88>', '<unk_89>', '<unk_90>', '<unk_91>', '<unk_92>', '<unk_93>', '<unk_94>', '<unk_95>', '<unk_96>', '<unk_97>', '<unk_98>', '<unk_99>', '<unk_100>', '<unk_101>', '<unk_102>']})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuaration of tokenizer\n",
    "tokenizer_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the model\n",
    "# model_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568699904\n"
     ]
    }
   ],
   "source": [
    "# number of trainable parameters\n",
    "model_large_params = sum(p.numel() for p in model_large.parameters() if p.requires_grad)\n",
    "print(model_large_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlWzhUKM3EB0"
   },
   "source": [
    "### Testing the pretrained Pegasus model on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get summary of a text of list of texts\n",
    "def get_summary(tokenizer, model, x):\n",
    "    x_tokenized = tokenizer(x, truncation=True, padding = True, return_tensors=\"pt\").to(torch_device)\n",
    "    print(\"Input X tokenized. Generating Summary ...\")\n",
    "    y_pred_tokenized= model.generate(**x_tokenized).to(torch_device)\n",
    "    print(\"Summary Generated. Decoding Summary ...\")\n",
    "    y_pred = tokenizer.batch_decode(y_pred_tokenized, skip_special_tokens=True)\n",
    "    print(\"Summary Decoded.\")\n",
    "    return y_pred\n",
    "\n",
    "# function to caluculate rogue score\n",
    "def calculate_rouge(m, y_pred, y):\n",
    "    candidate = [i.split() for i in y_pred]\n",
    "    reference = [i.split() for i in y]\n",
    "    # print(candidate, reference)\n",
    "    \n",
    "    m.update((candidate, reference))\n",
    "    \n",
    "    return m.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Input X tokenized. Generating Summary ...\n",
      "Summary Generated. Decoding Summary ...\n",
      "Summary Decoded.\n",
      "{'Rouge-L-P': 0.027428257223599803, 'Rouge-L-R': 0.13904761904761906, 'Rouge-L-F': 0.13904761904761906, 'Rouge-1-P': 0.027428257223599803, 'Rouge-1-R': 0.13904761904761906, 'Rouge-1-F': 0.13904761904761906}\n",
      "CPU times: user 52min 21s, sys: 53min 50s, total: 1h 46min 12s\n",
      "Wall time: 28min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = Rouge(variants=[\"L\", 1], multiref=\"best\")\n",
    "\n",
    "for i in range(0,25, 25):\n",
    "    y_test_pred = get_summary(tokenizer_large,model_large, x_test_list[i:i+25])\n",
    "    r = calculate_rouge(m, y_test_pred, y_test_list[i:i+25])\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The world's largest cruise ship, which is 1,188 feet long and weighs 228,000 tonnes, has been delivered to cruise line Royal Caribbean ahead of its maiden voyage. The 'Symphony of the Seas' ship features a zipline and an ice rink. It has over 2,700 guest rooms, including two-storey family suites that have a slide connecting the second and first floors.\",\n",
       " 'Debt-ridden Air India has received a loan worth â\\x82¹1,500 crore from Bank of India to meet urgent working capital needs, according to reports. This comes less than a month after Air India floated a tender in this regard. Prior to this, the airline had reportedly borrowed around â\\x82¹3,250 crore as short-tenure loans from IndusInd Bank and Punjab National Bank.',\n",
       " 'China-based scientists have discovered a method to convert tree leaves into a porous carbon material that can be used to make electronics. Dried phoenix tree leaves, when grounded and heated to 220 ÂºC, produced a powder of carbon microspheres. On further heating with chemical treatment, the powder developed charge-holding capacity three times that of graphene supercapacitors, researchers said.',\n",
       " 'Investor Michael Novogratz halted his plan to launch a $500 million hedge fund in cryptocurrencies and predicted that Bitcoin could drop to as low as $8,000 before rebounding. Novogratz said, \"We didn\\'t like market conditions and we wanted to re-evaluate what we\\'re doing.\" He further added, \"I didn\\'t want to have to deal with the schizophrenic emotional side of it.\"',\n",
       " 'Silicon Valley-based juicer making startup Juicero is refunding all its customers after they discovered the chopped fruit packs the startup provides with the juicers can be hand-squeezed to obtain the juice. Juicero had said its â\\x82¹26,000 juicer applies four tons of force to the packs to squeeze the juice. However, its users managed to squeeze the pack without the juicer.',\n",
       " 'A parliamentary panel has reportedly summoned RBI Governor Urjit Patel to appear before it on May 17 to answer queries on the recently-unearthed banking scams. Patel had earlier said that the RBI doesn\\'t have adequate powers to deal with public sector banks. \"We would like to know what kind of powers the RBI Governor needs,\" a panel official said.',\n",
       " 'Markets regulator SEBI on Friday allowed stock exchanges to extend trading in equity derivatives by over 8.5 hours to bring the timings in line with commodity markets. It has allowed exchanges to set trading hours in equity derivatives between 9:00 am and 11:55 pm, effective October 1, 2018. As of now, trading is allowed from 9:15 am till 3:30 pm.',\n",
       " \"The trailer of actress Manisha Koirala's comeback film 'Dear Maya' has been released. The film will revolve around the story of a lonely middle-aged spinster, portrayed by Manisha. Written and directed by Sunaina Bhatnagar, the film also stars Pakistani VJ Madiha Imam and is scheduled to release on June 2.\",\n",
       " 'Speaking about being trolled for her dialogue, \"My business is my business, none of your business\" in the film \\'Race 3\\', actress Daisy Shah said that the memes made her more popular. \"[E]ither you take it positively or you take it negatively, and I take it positively,\" the actress added. She further said she was \"very happy\" with the outcome.',\n",
       " 'A Bangladesh court on Monday sentenced former Prime Minister Khaleda Zia to seven years in jail on corruption charges. Zia was found guilty of corruption charges linked to the misappropriation of â\\x82¹2.7 crore set aside for the Zia Charitable Trust Fund. In February, another court sentenced her to five years in jail for embezzling â\\x82¹1.8 crore meant for an orphanage.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The 'Symphony of the Seas' ship features a zipline and an ice rink.\",\n",
       " 'Debt-ridden Air India has received a loan worth 11,500 crore from Bank of India to meet urgent working capital needs, according to reports.',\n",
       " 'Dried phoenix tree leaves, when grounded and heated to 220 oC, produced a powder of carbon microspheres.',\n",
       " 'Novogratz said, \"We didn\\'t like market conditions and we wanted to re-evaluate what we\\'re doing.\" He further added, \"I didn\\'t want to have to deal with the schizophrenic emotional side of it.\"',\n",
       " 'Juicero had said its 126,000 juicer applies four tons of force to the packs to squeeze the juice.',\n",
       " '\"We would like to know what kind of powers the RBI Governor needs,\" a panel official said.',\n",
       " 'It has allowed exchanges to set trading hours in equity derivatives between 9:00 am and 11:55 pm, effective October 1, 2018.',\n",
       " 'The film will revolve around the story of a lonely middle-aged spinster, portrayed by Manisha.',\n",
       " 'Speaking about being trolled for her dialogue, \"My business is my business, none of your business\" in the film \\'Race 3\\', actress Daisy Shah said that the memes made her more popular.',\n",
       " 'A Bangladesh court on Monday sentenced former Prime Minister Khaleda Zia to seven years in jail on corruption charges.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"World's largest cruise ship with zipline, ice rink delivered\",\n",
       " 'Air India gets â\\x82¹1,500-crore loan from Bank of India',\n",
       " 'Scientists convert dried tree leaves into electronics',\n",
       " 'Investor halts plan for $500 mn cryptocurrency hedge fund',\n",
       " 'Juicer startup refunds users on hand-squeezing fruit packs',\n",
       " 'Parliamentary panel summons RBI Governor over bank scams',\n",
       " \"Exchanges allowed to extend equity derivatives' trading time\",\n",
       " \"Trailer of Manisha Koirala's comeback film 'Dear Maya' out\",\n",
       " \"I've become more popular since 'Race 3' memes: Daisy Shah\",\n",
       " \"Former B'desh PM Khaleda Zia jailed for 7 years in corruption case\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1652117631173,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "lFJ_0ZNq4loa",
    "outputId": "1397bcef-d9db-44ba-d795-2edee571a818"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1652106910890,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "Dr0fDeGJPqh6",
    "outputId": "a5760772-ef63-4d0f-a23a-4ddb1e5e34ee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1652107924833,
     "user": {
      "displayName": "Kuber Shahi",
      "userId": "04157404054756166055"
     },
     "user_tz": -330
    },
    "id": "0ostHsqJQCNr",
    "outputId": "79ba5d1a-db57-43e1-e112-249d5d674d87"
   },
   "source": [
    "### Preparing our training dataset for finetuning our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class to efficiently manage our dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, summary):\n",
    "        self.text= text\n",
    "        self.summary = summary\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.text.items()}\n",
    "        item['labels'] = torch.tensor(self.summary['input_ids'][idx])  # torch.tensor(self.summary[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.text['input_ids'])\n",
    "\n",
    "# function to prepare training data for model fine-tuning\n",
    "def prepare_data(tokenizer, x_train, y_train, x_val=None, y_val=None):\n",
    "    \n",
    "    val = False if x_val is None or y_val is None else True\n",
    "    def tokenize_data(text, summary):\n",
    "        text_tokenized = tokenizer(text, truncation=True, padding=True)\n",
    "        summary_tokenized = tokenizer(summary, truncation=True, padding=True)\n",
    "        dataset_tokenized = Dataset(text_tokenized, summary_tokenized)\n",
    "        return dataset_tokenized\n",
    "    \n",
    "    train_dataset = tokenize_data(x_train, y_train)\n",
    "    val_dataset = tokenize_data (x_val, y_val) if val else None\n",
    "    \n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare and configure base model for fine-tuning\n",
    "def prepare_finetuning(model, train_dataset, val_dataset=None, freeze_encoder=False, output_dir='./results'):\n",
    "\n",
    "  if freeze_encoder:                                # if freeze_encoder is true\n",
    "    for param in model.model.encoder.parameters():  # freeze the encode parameters\n",
    "      param.requires_grad = False\n",
    "\n",
    "  if val_dataset is not None:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=output_dir,            # output directory\n",
    "      adafactor=True,                   # use adafactor instead of AdamW\n",
    "      num_train_epochs=10,              # total number of training epochs\n",
    "      per_device_train_batch_size=8,    # batch size per device during training\n",
    "      per_device_eval_batch_size=8,     # batch size for evaluation\n",
    "      save_steps=500,                   # number of updates steps before checkpoint saves\n",
    "      save_total_limit=5,               # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "      evaluation_strategy='steps',      # evaluation strategy to adopt during training\n",
    "      eval_steps=100,                   # number of update steps before evaluation\n",
    "      warmup_steps=500,                 # number of warmup steps for learning rate scheduler\n",
    "      weight_decay=0.01,                # strength of weight decay\n",
    "      logging_dir='./logs',             # directory for storing logs\n",
    "      logging_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=model,                         # the instantiated transformer model\n",
    "      args=training_args,                  # training arguments as defined above\n",
    "      train_dataset=train_dataset,         # training dataset\n",
    "      eval_dataset=val_dataset             # evaluation dataset\n",
    "    )\n",
    "\n",
    "  else:\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=output_dir,           # output directory\n",
    "      adafactor=True,                  # use adafactor instead of AdamW\n",
    "      num_train_epochs=5,             # total number of training epochs\n",
    "      per_device_train_batch_size=10,   # batch size per device during training, can increase if memory allows\n",
    "      save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "      warmup_steps=50,                # number of warmup steps for learning rate scheduler\n",
    "      weight_decay=0.01,               # strength of weight decay\n",
    "      logging_dir='./logs',            # directory for storing logs\n",
    "      logging_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=model,                     # the instantiated transformer model\n",
    "      args=training_args,              # training arguments as defined above\n",
    "      train_dataset=train_dataset,     # training dataset\n",
    "    )\n",
    "\n",
    "  return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n"
     ]
    }
   ],
   "source": [
    "# tokenizing the training dataset\n",
    "train_dataset,_ = prepare_data(tokenizer_cnn, x_train_list[:1000], y_train_list[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 39 ms, total: 55 ms\n",
      "Wall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer = prepare_finetuning(model_large, train_dataset) # compile the trainer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model was finetuned on the HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The 'Symphony of the Seas' ship features a zipline and an ice rink.\",\n",
       " 'Debt-ridden Air India has received a loan worth 11,500 crore from Bank of India to meet urgent working capital needs, according to reports.',\n",
       " 'Dried phoenix tree leaves, when grounded and heated to 220 oC, produced a powder of carbon microspheres.',\n",
       " 'Novogratz said, \"We didn\\'t like market conditions and we wanted to re-evaluate what we\\'re doing.\" He further added, \"I didn\\'t want to have to deal with the schizophrenic emotional side of it.\"',\n",
       " 'Juicero had said its 126,000 juicer applies four tons of force to the packs to squeeze the juice.',\n",
       " '\"We would like to know what kind of powers the RBI Governor needs,\" a panel official said.',\n",
       " 'It has allowed exchanges to set trading hours in equity derivatives between 9:00 am and 11:55 pm, effective October 1, 2018.',\n",
       " 'The film will revolve around the story of a lonely middle-aged spinster, portrayed by Manisha.',\n",
       " 'Speaking about being trolled for her dialogue, \"My business is my business, none of your business\" in the film \\'Race 3\\', actress Daisy Shah said that the memes made her more popular.',\n",
       " 'A Bangladesh court on Monday sentenced former Prime Minister Khaleda Zia to seven years in jail on corruption charges.']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base model prediction\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"World's largest cruise ship with zipline, ice rink delivered\",\n",
       " 'Air India gets â\\x82¹1,500-crore loan from Bank of India',\n",
       " 'Scientists convert dried tree leaves into electronics',\n",
       " 'Investor halts plan for $500 mn cryptocurrency hedge fund',\n",
       " 'Juicer startup refunds users on hand-squeezing fruit packs',\n",
       " 'Parliamentary panel summons RBI Governor over bank scams',\n",
       " \"Exchanges allowed to extend equity derivatives' trading time\",\n",
       " \"Trailer of Manisha Koirala's comeback film 'Dear Maya' out\",\n",
       " \"I've become more popular since 'Race 3' memes: Daisy Shah\",\n",
       " \"Former B'desh PM Khaleda Zia jailed for 7 years in corruption case\"]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.11.0+cu102\n",
      "Available Torc Device: cpu\n",
      "\n",
      "Reading the Dataset...\n",
      "(98401, 2)\n",
      "\n",
      "Splitting the Dataset...\n",
      "(78720,) (78720,)\n",
      "(19681,) (19681,)\n",
      "Length of the Training and Test Set...\n",
      "78720 78720\n",
      "19681 19681\n",
      "\n",
      "Tokenizing the dataset\n",
      "Length of the dataset: 1000\n",
      "\n",
      "Preparing model_large for finetuning...\n",
      "\n",
      "Training...\n",
      "{'loss': 9.0646, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 8.5442, 'learning_rate': 2e-05, 'epoch': 0.2}\n",
      "{'loss': 7.845, 'learning_rate': 3e-05, 'epoch': 0.3}\n",
      "{'loss': 7.4245, 'learning_rate': 4e-05, 'epoch': 0.4}\n",
      "{'loss': 6.7786, 'learning_rate': 5e-05, 'epoch': 0.5}\n",
      "{'loss': 6.4331, 'learning_rate': 4.888888888888889e-05, 'epoch': 0.6}\n",
      "{'loss': 6.2427, 'learning_rate': 4.7777777777777784e-05, 'epoch': 0.7}\n",
      "{'loss': 6.2779, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.8}\n",
      "{'loss': 5.8455, 'learning_rate': 4.555555555555556e-05, 'epoch': 0.9}\n",
      "{'loss': 5.6898, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.0}\n",
      "{'loss': 5.6552, 'learning_rate': 4.3333333333333334e-05, 'epoch': 1.1}\n",
      "{'loss': 5.6679, 'learning_rate': 4.222222222222222e-05, 'epoch': 1.2}\n",
      "{'loss': 5.5837, 'learning_rate': 4.111111111111111e-05, 'epoch': 1.3}\n",
      "{'loss': 5.5092, 'learning_rate': 4e-05, 'epoch': 1.4}\n",
      "{'loss': 5.5528, 'learning_rate': 3.888888888888889e-05, 'epoch': 1.5}\n",
      "{'loss': 5.4032, 'learning_rate': 3.777777777777778e-05, 'epoch': 1.6}\n",
      "{'loss': 5.3617, 'learning_rate': 3.6666666666666666e-05, 'epoch': 1.7}\n",
      "{'loss': 5.3132, 'learning_rate': 3.555555555555556e-05, 'epoch': 1.8}\n",
      "{'loss': 5.2191, 'learning_rate': 3.444444444444445e-05, 'epoch': 1.9}\n",
      "{'loss': 5.1191, 'learning_rate': 3.3333333333333335e-05, 'epoch': 2.0}\n",
      "{'loss': 4.9922, 'learning_rate': 3.222222222222223e-05, 'epoch': 2.1}\n",
      "{'loss': 4.8054, 'learning_rate': 3.111111111111111e-05, 'epoch': 2.2}\n",
      "{'loss': 4.9336, 'learning_rate': 3e-05, 'epoch': 2.3}\n",
      "{'loss': 4.7505, 'learning_rate': 2.8888888888888888e-05, 'epoch': 2.4}\n",
      "{'loss': 4.8648, 'learning_rate': 2.777777777777778e-05, 'epoch': 2.5}\n",
      "{'loss': 4.7507, 'learning_rate': 2.6666666666666667e-05, 'epoch': 2.6}\n",
      "{'loss': 4.607, 'learning_rate': 2.5555555555555554e-05, 'epoch': 2.7}\n",
      "{'loss': 4.3708, 'learning_rate': 2.4444444444444445e-05, 'epoch': 2.8}\n",
      "{'loss': 4.3509, 'learning_rate': 2.3333333333333336e-05, 'epoch': 2.9}\n",
      "{'loss': 4.2739, 'learning_rate': 2.2222222222222223e-05, 'epoch': 3.0}\n",
      "{'loss': 4.0727, 'learning_rate': 2.111111111111111e-05, 'epoch': 3.1}\n",
      "{'loss': 3.788, 'learning_rate': 2e-05, 'epoch': 3.2}\n",
      "{'loss': 3.9351, 'learning_rate': 1.888888888888889e-05, 'epoch': 3.3}\n",
      "{'loss': 3.6126, 'learning_rate': 1.777777777777778e-05, 'epoch': 3.4}\n",
      "{'loss': 3.6046, 'learning_rate': 1.6666666666666667e-05, 'epoch': 3.5}\n",
      "{'loss': 3.3984, 'learning_rate': 1.5555555555555555e-05, 'epoch': 3.6}\n",
      "{'loss': 3.3468, 'learning_rate': 1.4444444444444444e-05, 'epoch': 3.7}\n",
      "{'loss': 3.3085, 'learning_rate': 1.3333333333333333e-05, 'epoch': 3.8}\n",
      "{'loss': 3.0717, 'learning_rate': 1.2222222222222222e-05, 'epoch': 3.9}\n",
      "{'loss': 3.0019, 'learning_rate': 1.1111111111111112e-05, 'epoch': 4.0}\n",
      "{'loss': 2.9165, 'learning_rate': 1e-05, 'epoch': 4.1}\n",
      "{'loss': 2.8464, 'learning_rate': 8.88888888888889e-06, 'epoch': 4.2}\n",
      "{'loss': 2.7701, 'learning_rate': 7.777777777777777e-06, 'epoch': 4.3}\n",
      "{'loss': 2.6228, 'learning_rate': 6.666666666666667e-06, 'epoch': 4.4}\n",
      "{'loss': 2.5978, 'learning_rate': 5.555555555555556e-06, 'epoch': 4.5}\n",
      "{'loss': 2.5329, 'learning_rate': 4.444444444444445e-06, 'epoch': 4.6}\n",
      "{'loss': 2.6701, 'learning_rate': 3.3333333333333333e-06, 'epoch': 4.7}\n",
      "{'loss': 2.5744, 'learning_rate': 2.2222222222222225e-06, 'epoch': 4.8}\n",
      "{'loss': 2.5231, 'learning_rate': 1.1111111111111112e-06, 'epoch': 4.9}\n",
      "{'loss': 2.5238, 'learning_rate': 0.0, 'epoch': 5.0}\n",
      "{'train_runtime': 4514.2918, 'train_samples_per_second': 1.108, 'train_steps_per_second': 0.111, 'train_loss': 4.6589766769409175, 'epoch': 5.0}\n",
      "\n",
      "End of Training...\n",
      "\n",
      "Testing the fineTuned model:\n",
      "Input X tokenized. Generating Summary ...\n",
      "Summary Generated. Decoding Summary ...\n",
      "Summary Decoded.\n",
      "\n",
      "Printing the predicted sumamry:\n",
      "\n",
      "[\"The world's largest cruise ship has been delivered\", 'Air India gets 11,500 crore loan from Bank of India', 'China-based scientists find way to make electronics from tree leaves', 'Bitcoin could fall to as low as $8,000 before rebounding', 'Silicon Valley-based startup Juicero to refund all customers after they discovered chopped fruit packs can be hand-squeezed to juice', 'RBI Governor Urjit summoned to appear before Parliament panel on bank scams', 'SEBI allows stock exchanges to extend trading hours in equity derivatives', \"Manisha Koirala's comeback film 'Dear Maya' trailer released\", 'My business is my business, none of your business: Daisy Shah', 'Khaleda sentenced to 7 years in jail on corruption charges']\n",
      "\n",
      "Calculating Rouge Score:\n",
      "\n",
      "Rouge Score: {'Rouge-L-P': 0.009429864253393665, 'Rouge-L-R': 0.08, 'Rouge-L-F': 0.08, 'Rouge-1-P': 0.009429864253393665, 'Rouge-1-R': 0.08, 'Rouge-1-F': 0.08}\n",
      "\n",
      "End of the job\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('train.log', 'r') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading finetuned model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./results/checkpoint-500/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading weights file ./results/checkpoint-500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at ./results/checkpoint-500/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./results/checkpoint-500/\"\n",
    "model_finetune = PegasusForConditionalGeneration.from_pretrained(model_path, local_files_only=True).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"Elon Musk said on Tuesday that he would “reverse the permanent ban” of former President Donald J. Trump on Twitter and let him back on the social network, in one of the first specific comments by Mr. Musk, the world’s richest man, of how he would change the social media service.\n",
    "\n",
    "Mr. Musk, who struck a deal last month to buy Twitter for $44 billion, said at a Financial Times conference that the company’s decision to bar Mr. Trump last year for tweets about the riots at the U.S. Capitol was “a mistake because it alienated a large part of the country and did not ultimately result in Donald Trump not having a voice.” He added that it was “morally wrong and flat-out stupid” and that “permanent bans just fundamentally undermine trust in Twitter.”\n",
    "\n",
    "Mr. Musk’s remarks were a preview of the kinds of sweeping changes he might make at Twitter, which he is expected to take ownership of in the next six months. The billionaire, who also leads the electric carmaker Tesla and the rocket company SpaceX, has called himself a “free speech absolutist” and has said he is unhappy with how Twitter decides what can and cannot be posted online.\n",
    "\n",
    "But up until Tuesday, Mr. Musk, 50, had spoken mostly in general terms and had not singled out Twitter accounts that might be affected by his takeover. He had called free speech “the bedrock of a functioning democracy” and had spoken of his desire to give people more control over their own social media feeds. By specifying that Mr. Trump could return to the platform, Mr. Musk uncorked a political firestorm.\n",
    "\n",
    "Mr. Trump wielded Twitter for many years as both a megaphone and a cudgel, rallying his 88 million followers on issues such as immigration while also going after opponents. That avenue was cut off in January 2021 when Twitter, along with Facebook and other platforms, barred Mr. Trump from posting in the wake of the attack on the U.S. Capitol building. Twitter said at the time that Mr. Trump had violated policies and risked inciting violence among his supporters. Fa\n",
    "\n",
    "cebook barred Mr. Trump for similar reasons.\n",
    "\n",
    "Mr. Trump, who has since begun a social media site called Truth Social, did not respond to a request for comment. Last month, Mr. Trump said that even with Mr. Musk buying Twitter, he did not plan to return to the platform and was “going to stay on Truth.”\n",
    "\n",
    "Twitter declined to comment.\n",
    "\n",
    "Derrick Johnson, the president of the N.A.A.C.P., said that free speech online needed to come with guardrails.\n",
    "\n",
    "“Mr. Musk: Free speech is wonderful, hate speech is unacceptable,” he said. “Do not allow 45 to return to the platform. Do not allow Twitter to become a petri dish for hate speech or falsehoods that subvert our democracy.”\n",
    "\n",
    "But Jack Dorsey, a founder and board member of Twitter, tweeted that permanent suspensions of individual users “are a failure” of the company and largely “don’t work.” Mr. Dorsey, who was chief executive of Twitter when Mr. Trump was barred, had said last year that booting the president was the right decision for the company, but backtracked on Tuesday by calling it “a business decision” and saying “it shouldn’t have been.”\n",
    "\n",
    "Even with Mr. Musk’s comments, Mr. Trump’s potential return to Twitter remains far from assured. Mr. Musk is mercurial and has a history of saying things he does not follow through on. In 2018, he famously declared that he planned to take Tesla private and had the funding to do so, when he did not. Even his most devoted followers sometimes wonder whether his obscurantist tweets are serious or are made in jest.\n",
    "\n",
    "Investors have also questioned whether Mr. Musk’s deal for Twitter will be completed. The company’s shares closed Tuesday at $47.26, well below the $54.20 that Mr. Musk agreed to pay for them. Mr. Musk is also still securing financing for his takeover. While venture-capital firms and some big banks have lined up to invest, the billionaire is on the hook to provide as much as $21 billion of his own cash. He has not detailed where he will obtain that money.\n",
    "\n",
    "Mr. Musk referred to the possibility of the deal not closing on Tuesday and of nothing happening with Mr. Trump’s Twitter account. “Obviously, I don’t own Twitter yet,” he said at the Financial Times conference. “So this is not a thing that will definitely happen because what if I don’t own Twitter.”\n",
    "\n",
    "Mr. Trump long bedeviled social media companies because of how he pushed the line on speech, sometimes spreading lies and bullying people. But the companies’ moves to bar him drew accusations, especially from conservatives, that they were engaging in censorship and were biased against Republican voices.\n",
    "\n",
    "Mr. Musk seemed to echo some of those conservative complaints on Tuesday, accusing Twitter of “a strong left bias, because it’s based in San Francisco” and saying “victory would be that the most far-right 10 percent and the most far-left 10 percent are equally upset.”\n",
    "\n",
    "Some of the companies have since shied from appearing as the final word on who gets to say what online. Facebook referred Mr. Trump’s case to its Oversight Board, a company-appointed panel of academics, journalists and former members of government. The board ruled that Facebook was right to bar Mr. Trump, but it said the company had not thoroughly explained its decision and should revisit an indefinite suspension.\n",
    "\n",
    "In June, Facebook said Mr. Trump’s ban would last at least two years, keeping the former president off the site through the 2022 midterm elections.\n",
    "\n",
    "When Mr. Musk began buying up shares of Twitter this year, he started voicing more of his thoughts about the service and free speech, including in exchanges with Mr. Dorsey. In March, Mr. Musk asked his followers if Twitter was failing to adhere to free speech principles.\n",
    "\n",
    "“Free speech is essential to a functioning democracy. Do you believe Twitter rigorously adheres to this principle?” he asked.\n",
    "\n",
    "At another point, Mr. Musk wondered, “Is a new platform needed?”\n",
    "\n",
    "After Mr. Musk inked the deal to buy Twitter last month, he reiterated his free speech stance and said he would take the company private to improve the service. He added that he hoped to increase trust by making Twitter’s technology more transparent, defeating the bots that spam people on the platform and “authenticating all humans.” He also said he hoped his worst critics would remain on Twitter, because “that is what free speech means.”\n",
    "\n",
    "On Tuesday, he became more specific. “Permanent bans should be extremely rare,” Mr. Musk said, adding that they should be reserved “for accounts that are bots or spam” and “where there’s just no legitimacy to the account at all.”\n",
    "\n",
    "But he also said that “doesn’t mean that somebody gets to say whatever they want to say.” Mr. Musk said he was in favor of temporary suspensions of accounts “if they say something that is illegal or otherwise just, you know, destructive to the world.” He also raised the idea that a particular tweet could be “made invisible or have very limited traction.”\n",
    "\n",
    "Apart from Mr. Trump, others who have been indefinitely barred from Twitter for violating its policies include Representative Marjorie Taylor Greene, Republican of Georgia, the far-right figure Milo Yiannopoulos, and celebrities like Tila Tequila. Twitter also labels tweets that are factually inaccurate or that might incite violence.\n",
    "\n",
    "Inside Twitter on Tuesday, some employees worried that Mr. Musk’s changes would unwind years of work on the company’s policies and unravel millions of dollars of investment in content moderation to stem abuse on the platform, four current and former employees said. Some said they hoped Mr. Musk would lose interest in the site, while others have begun reaching out to recruiters and friends at other tech companies for new opportunities.\n",
    "\n",
    "Still others were excited at the prospect of Mr. Musk in charge, the current and former employees said. Mr. Musk has pitched investors on quintupling Twitter’s revenue and on the service topping more than 900 million users by 2028, up from 217 million or so today.\n",
    "\n",
    "Michael C. Bender and Lauren Hirsch contributed reporting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Input X tokenized. Generating Summary ...\n",
      "Summary Generated. Decoding Summary ...\n",
      "Summary Decoded.\n",
      "['Elon Musk said on Tuesday that he would “reverse the permanent ban” of former President Donald J. Trump on Twitter and let him back on the social network, in one of the first specific comments by Mr. Musk, who struck a deal last month to buy Twitter for $44 billion, said at a Financial Times conference that the company’s decision to bar Mr. The billionaire, who also leads the electric carmaker Tesla and the rocket company SpaceX, has called himself a “free speech absolutist” and has said he is unhappy with how Twitter decides what can and cannot be posted online.']\n",
      "CPU times: user 5min 4s, sys: 5min 6s, total: 10min 11s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_summary = get_summary(tokenizer_large, model_large, test_text)\n",
    "print(text_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Input X tokenized. Generating Summary ...\n",
      "Summary Generated. Decoding Summary ...\n",
      "Summary Decoded.\n",
      "['Elon Musk says he will reverse ban on Trump on Twitter']\n",
      "CPU times: user 38.4 s, sys: 31.8 s, total: 1min 10s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_headline = get_summary(tokenizer_large, model_finetune, text_summary)\n",
    "print(text_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Input X tokenized. Generating Summary ...\n",
      "Summary Generated. Decoding Summary ...\n",
      "Summary Decoded.\n",
      "['Musk, who struck a deal last month to buy Twitter for $44 billion, said at a Financial Times conference that the company’s decision to bar Mr.']\n",
      "CPU times: user 2min 33s, sys: 2min 14s, total: 4min 48s\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_headline = get_summary(tokenizer_large, model_large, text_summary)\n",
    "print(text_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyOx+LFhBD37vffFG7idB6n/",
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
